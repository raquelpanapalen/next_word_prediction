{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "from main import get_model\n",
    "from dataset.dataset import LoaderConstructor, create_alicewonderland_dataset, create_rocstories_dataset\n",
    "\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'dataset': 'rocstories',\n",
    "    'batch_size': 3,\n",
    "    'max_length': 20,\n",
    "    'embed_dim': 512,\n",
    "    'min_text_length': 100, \n",
    "    'tokenizer': 'torchtext'\n",
    "}\n",
    "\n",
    "# Load the dataset\n",
    "if \"wikitest\" in cfg['dataset']:\n",
    "    dataset = load_dataset(\"wikitext\", f\"{cfg['dataset']}-raw-v1\")\n",
    "    for split in dataset.keys():\n",
    "        dataset[split] = dataset[split].filter(\n",
    "            lambda x: len(x[\"text\"]) > cfg.min_text_length\n",
    "        )\n",
    "\n",
    "elif cfg['dataset'] == \"rocstories\":\n",
    "    dataset = create_rocstories_dataset(os.getcwd())\n",
    "elif cfg['dataset'] == \"alicewonderland\":\n",
    "    dataset = create_alicewonderland_dataset(os.getcwd())\n",
    "\n",
    "# Construct the dataloaders\n",
    "lc = LoaderConstructor(\n",
    "    dataset=dataset,\n",
    "    batch_size=cfg['batch_size'],\n",
    "    max_length=cfg['max_length'],\n",
    "    tokenizer_type=cfg['tokenizer'],\n",
    "    labels_sequence=False,\n",
    ")\n",
    "loaders = {}\n",
    "for loader in [\"train\", \"validation\", \"test\"]:\n",
    "    loaders[loader] = lc.construct_loader(split=loader)\n",
    "\n",
    "input_size = loaders[\"train\"].dataset.input_size\n",
    "vocab_size = lc.vocab_size\n",
    "output_size = lc.output_size\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name):\n",
    "    model = get_model(\n",
    "        model=model_name,\n",
    "        vocab_size=vocab_size,\n",
    "        embed_dim=cfg['embed_dim'],\n",
    "        seq_len=input_size,\n",
    "        output_dim=output_size,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    model_weights = {\n",
    "        'lstm': f\"trained_models/lstm_{cfg['dataset']}_lr=0_0001_lastepoch.pt\",\n",
    "        'transformer': f\"trained_models/transformer_{cfg['dataset']}_lr=0_0001_lastepoch.pt\",\n",
    "        'xlstm': f\"trained_models/xlstm_{cfg['dataset']}_lr=0_0001_lastepoch.pt\",\n",
    "    }\n",
    "\n",
    "    model.load_state_dict(torch.load(model_weights[model_name]))\n",
    "    model.to(device).eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, batch, test=False, n_next_words=5):    \n",
    "    # Forward pass\n",
    "    inputs, labels = batch[\"input_ids\"].to(device), batch[\"labels\"].to(device)\n",
    "    labels = labels.contiguous().view(-1)\n",
    "    output = model(inputs).view(-1, output_size)\n",
    "\n",
    "    for i in range(batch[\"input_ids\"].shape[0]):\n",
    "        print(f\"Input sentence: {lc.tokenizer.decode(inputs[i].tolist(), target=False)}\")\n",
    "        print(\n",
    "            f\"Target sentence: {lc.tokenizer.decode(labels[i].unsqueeze(0).tolist(), target=True)}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Predicted sentence: {lc.tokenizer.decode(torch.argmax(output[i], dim=-1).unsqueeze(0).tolist(), target=True)}\"\n",
    "        )\n",
    "        print()\n",
    "        \n",
    "    # Predict next words\n",
    "    if test:\n",
    "        mini_dataset = [\n",
    "            {\"text\": \"The quick brown fox jumps over the lazy dog and then went\", \"predictions\": []},\n",
    "            {\"text\": \"I can't wait to\", \"predictions\": []},\n",
    "            {\"text\": \"The capital of France is Paris, a city full of\", \"predictions\": []},\n",
    "            {\"text\": \"The best way to learn mathemathics\", \"predictions\": []},\n",
    "            {\"text\": \"I am so mad, my boss is always\", \"predictions\": []},\n",
    "        ]\n",
    "\n",
    "        # Tokenize the texts\n",
    "        tokenised_samples = lc.tokenizer.create_tokens(mini_dataset)\n",
    "        tokenised_samples = lc.tokenizer.pad_sequences(tokenised_samples)\n",
    "        encodings = lc.tokenizer.encode(tokenised_samples)\n",
    "\n",
    "        # No labels in this case\n",
    "        inputs = encodings[:, 1:].to(device)\n",
    "        with torch.no_grad():\n",
    "            for _ in range(n_next_words):\n",
    "                output = model(inputs)\n",
    "                next_token = torch.argmax(output, dim=-1)\n",
    "                for i in range(len(mini_dataset)):\n",
    "                    mini_dataset[i][\"predictions\"].append(\n",
    "                        lc.tokenizer.decode(next_token[i].unsqueeze(0).tolist(), target=True)\n",
    "                    )\n",
    "                inputs = torch.cat([inputs[:, 1:], next_token.reshape(-1, 1)], dim=1)\n",
    "\n",
    "        for sample in mini_dataset:\n",
    "            print(f\"Input sentence: {sample['text']}\")\n",
    "            print(f\"Predicted next words: {' '.join(sample['predictions'])}\")\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Evaluating model: xlstm\n",
      "**************************************************\n",
      "Input sentence: jane was asleep when a thunderstorm started outside she didn realize that the electricity went out when she woke up\n",
      "Target sentence: it\n",
      "Predicted sentence: it\n",
      "\n",
      "Input sentence: tim and jessica were in a long term relationship together one day jessica ended the relationship tim cried and wept\n",
      "Target sentence: for\n",
      "Predicted sentence: for\n",
      "\n",
      "Input sentence: his bed shook he turned on the news and learned about the <oov> jake was calm and thought it was\n",
      "Target sentence: interesting\n",
      "Predicted sentence: interesting\n",
      "\n",
      "**************************************************\n",
      "**************************************************\n",
      "Evaluating model: lstm\n",
      "**************************************************\n",
      "Input sentence: jane was asleep when a thunderstorm started outside she didn realize that the electricity went out when she woke up\n",
      "Target sentence: it\n",
      "Predicted sentence: it\n",
      "\n",
      "Input sentence: tim and jessica were in a long term relationship together one day jessica ended the relationship tim cried and wept\n",
      "Target sentence: for\n",
      "Predicted sentence: for\n",
      "\n",
      "Input sentence: his bed shook he turned on the news and learned about the <oov> jake was calm and thought it was\n",
      "Target sentence: interesting\n",
      "Predicted sentence: interesting\n",
      "\n",
      "**************************************************\n",
      "**************************************************\n",
      "Evaluating model: transformer\n",
      "**************************************************\n",
      "Input sentence: jane was asleep when a thunderstorm started outside she didn realize that the electricity went out when she woke up\n",
      "Target sentence: it\n",
      "Predicted sentence: it\n",
      "\n",
      "Input sentence: tim and jessica were in a long term relationship together one day jessica ended the relationship tim cried and wept\n",
      "Target sentence: for\n",
      "Predicted sentence: for\n",
      "\n",
      "Input sentence: his bed shook he turned on the news and learned about the <oov> jake was calm and thought it was\n",
      "Target sentence: interesting\n",
      "Predicted sentence: interesting\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(loaders[\"train\"]))\n",
    "for model_name in [\"xlstm\", \"lstm\", \"transformer\"]:\n",
    "    print('*' * 50)\n",
    "    print(f\"Evaluating model: {model_name}\")\n",
    "    print('*' * 50)\n",
    "    model = initialize_model(model_name)\n",
    "    evaluate(model, batch)\n",
    "    print('*' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Evaluating model: xlstm\n",
      "**************************************************\n",
      "Input sentence: stormy asked if i could be her new mama she asked because she was little and didn know who her\n",
      "Target sentence: mother\n",
      "Predicted sentence: phone\n",
      "\n",
      "Input sentence: mary was an animal care specialist at a dog and cat rescue shelter she could usually work with even the\n",
      "Target sentence: most\n",
      "Predicted sentence: one\n",
      "\n",
      "Input sentence: fred exercised a lot and was a very healthy person he enjoyed running every evening one evening he felt a\n",
      "Target sentence: little\n",
      "Predicted sentence: cold\n",
      "\n",
      "Input sentence: The quick brown fox jumps over the lazy dog and then went\n",
      "Predicted next words: to had the were to had the were to but as up everyone with got son was talk last the\n",
      "\n",
      "Input sentence: I can't wait to\n",
      "Predicted next words: never to now about one to she at died to could his to made a job a food ryan later\n",
      "\n",
      "Input sentence: The capital of France is Paris, a city full of\n",
      "Predicted next words: flowers they it children and would on to and doesn to in on been the he loud that the he\n",
      "\n",
      "Input sentence: The best way to learn mathemathics\n",
      "Predicted next words: now going followed she able son when to now the were to she able liked her already the it she\n",
      "\n",
      "Input sentence: I am so mad, my boss is always\n",
      "Predicted next words: to could at got way work me they me they years she my of needed and is a house few\n",
      "\n",
      "**************************************************\n",
      "**************************************************\n",
      "Evaluating model: lstm\n",
      "**************************************************\n",
      "Input sentence: stormy asked if i could be her new mama she asked because she was little and didn know who her\n",
      "Target sentence: mother\n",
      "Predicted sentence: mom\n",
      "\n",
      "Input sentence: mary was an animal care specialist at a dog and cat rescue shelter she could usually work with even the\n",
      "Target sentence: most\n",
      "Predicted sentence: dog\n",
      "\n",
      "Input sentence: fred exercised a lot and was a very healthy person he enjoyed running every evening one evening he felt a\n",
      "Target sentence: little\n",
      "Predicted sentence: very\n",
      "\n",
      "Input sentence: The quick brown fox jumps over the lazy dog and then went\n",
      "Predicted next words: home to with were to to a next of had a restaurant of had the with had the of had\n",
      "\n",
      "Input sentence: I can't wait to\n",
      "Predicted next words: stay my my my my day to my day to to there a yard finally to from a kitchen of\n",
      "\n",
      "Input sentence: The capital of France is Paris, a city full of\n",
      "Predicted next words: berries plants satisfied satisfied satisfied because i family is out when so night a way home to to and took\n",
      "\n",
      "Input sentence: The best way to learn mathemathics\n",
      "Predicted next words: my year came to my hope my morning to to onto a rules of couldn seen a next from a\n",
      "\n",
      "Input sentence: I am so mad, my boss is always\n",
      "Predicted next words: have my my my day to my day to my day to to a engine finally to with loved to\n",
      "\n",
      "**************************************************\n",
      "**************************************************\n",
      "Evaluating model: transformer\n",
      "**************************************************\n",
      "Input sentence: stormy asked if i could be her new mama she asked because she was little and didn know who her\n",
      "Target sentence: mother\n",
      "Predicted sentence: she\n",
      "\n",
      "Input sentence: mary was an animal care specialist at a dog and cat rescue shelter she could usually work with even the\n",
      "Target sentence: most\n",
      "Predicted sentence: cat\n",
      "\n",
      "Input sentence: fred exercised a lot and was a very healthy person he enjoyed running every evening one evening he felt a\n",
      "Target sentence: little\n",
      "Predicted sentence: lot\n",
      "\n",
      "Input sentence: The quick brown fox jumps over the lazy dog and then went\n",
      "Predicted next words: to to into into board away the away suddenly out soon the see jan with loved and was fix a\n",
      "\n",
      "Input sentence: I can't wait to\n",
      "Predicted next words: buy him night a most organized of could looking a most going to children as liked them accident life with\n",
      "\n",
      "Input sentence: The capital of France is Paris, a city full of\n",
      "Predicted next words: loud soon to into stan looking them accident life that the many picked up an impressed happy care to to\n",
      "\n",
      "Input sentence: The best way to learn mathemathics\n",
      "Predicted next words: his into into board about part into board about different of am grandparents friends best to is some for this\n",
      "\n",
      "Input sentence: I am so mad, my boss is always\n",
      "Predicted next words: wear night how games him he winning day to one he woman at fb ultimately food the on never if\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(loaders[\"test\"]))\n",
    "for model_name in [\"xlstm\", \"lstm\", \"transformer\"]:\n",
    "    print('*' * 50)\n",
    "    print(f\"Evaluating model: {model_name}\")\n",
    "    print('*' * 50)\n",
    "    model = initialize_model(model_name)\n",
    "    evaluate(model, batch, test=True, n_next_words=20)\n",
    "    print('*' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
